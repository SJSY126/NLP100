{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[参考](https://qiita.com/nymwa/items/9c8484ff511123e03ba8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "categories = ['b', 't', 'e', 'm']\n",
    "category_names = ['business', 'science and technology', 'entertainment', 'health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x = re.sub(r'\\s+', ' ', x)\n",
    "    x = nlp.make_doc(x)\n",
    "    x = [d.text for d in x]\n",
    "    return x\n",
    "\n",
    "def read_feature_dataset(filename):\n",
    "    with open(filename) as f:\n",
    "        dataset = f.read().splitlines()\n",
    "    dataset = [line.split('\\t') for line in dataset]\n",
    "    t_index = [categories.index(line[0]) for line in dataset]\n",
    "    dataset_t = []\n",
    "    for index in t_index:\n",
    "        label = [0]*4\n",
    "        label[index] = 1\n",
    "        dataset_t.append(label)\n",
    "    dataset_x = [tokenize(line[1]) for line in dataset]\n",
    "    return dataset_x, dataset_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_t = read_feature_dataset('train.txt')\n",
    "valid_x, valid_t = read_feature_dataset('valid.txt')\n",
    "test_x, test_t = read_feature_dataset('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load('GoogleNews-vectors-negative300.kv', mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x10acfd3d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tenosrflowでいきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_vector(sent):\n",
    "    lst = [tf.constant(model[token]) for token in sent if token in model]\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def dataset_to_vector(dataset):\n",
    "    return tf.stack([sent_to_vector(x) for x in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_v = dataset_to_vector(train_x)\n",
    "valid_v = dataset_to_vector(valid_x)\n",
    "test_v = dataset_to_vector(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t = tf.constant(train_t)\n",
    "valid_t = tf.constant(valid_t)\n",
    "test_t = tf.constant(test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.feature.pickle', 'wb') as f:\n",
    "    pickle.dump(train_v, f)\n",
    "with open('data/train.label.pickle', 'wb') as f:\n",
    "    pickle.dump(train_t, f)\n",
    "\n",
    "with open('data/valid.feature.pickle', 'wb') as f:\n",
    "    pickle.dump(valid_v, f)\n",
    "with open('data/valid.label.pickle', 'wb') as f:\n",
    "    pickle.dump(valid_t, f)\n",
    "\n",
    "with open('data/test.feature.pickle', 'wb') as f:\n",
    "    pickle.dump(test_v, f)\n",
    "with open('data/test.label.pickle', 'wb') as f:\n",
    "    pickle.dump(test_t, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10684, 300])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(tf.keras.Model):\n",
    "    def __init__(self, out_dim, name=\"NN\"):\n",
    "        super().__init__(name=name)\n",
    "        self.out_dim = out_dim\n",
    "        self.l1 = tf.keras.layers.Dense(\n",
    "            self.out_dim, \n",
    "            use_bias=False, \n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        y = self.l1(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.2334692  0.27815533 0.2055894  0.28278604]\n",
      " [0.24997279 0.25695467 0.23655325 0.25651932]\n",
      " [0.26750898 0.24725448 0.25268868 0.2325479 ]\n",
      " [0.26104128 0.27834803 0.23206748 0.2285432 ]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = model(train_v[:4])\n",
    "y = tf.nn.softmax(x, axis=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(tf.keras.Model):\n",
    "    def __init__(self, out_dim, name=\"NN\"):\n",
    "        super().__init__(name=name)\n",
    "        self.out_dim = out_dim\n",
    "        self.l1 = tf.keras.layers.Dense(\n",
    "            self.out_dim, \n",
    "            use_bias=False, \n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        y = tf.nn.softmax(self.l1(x))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = NN(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(t, y):\n",
    "    return tf.keras.backend.mean(tf.keras.losses.categorical_crossentropy(t,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.3457048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(train_t, model(train_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'NN/dense_1/kernel:0' shape=(300, 4) dtype=float32, numpy=\n",
       " array([[-0.02457763,  0.05170919, -0.00212602, -0.08934447],\n",
       "        [ 0.08095491,  0.10621148,  0.02188836, -0.03038672],\n",
       "        [ 0.07699631, -0.09801296,  0.1181428 ,  0.12297057],\n",
       "        ...,\n",
       "        [ 0.09177855, -0.01307347,  0.09992485, -0.00326847],\n",
       "        [-0.13962416, -0.05638149, -0.02081947,  0.003896  ],\n",
       "        [ 0.08044873, -0.06248715, -0.12428132,  0.03352007]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    current_loss = loss(train_t, model(train_v))\n",
    "dW = t.gradient(current_loss, [model.weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "損失 tf.Tensor(1.3457048, shape=(), dtype=float32)\n",
      "勾配 [[<tf.Tensor: shape=(300, 4), dtype=float32, numpy=\n",
      "array([[ 0.00271831,  0.00213254, -0.00975994,  0.00490909],\n",
      "       [-0.00364486,  0.00306664, -0.00378065,  0.00435887],\n",
      "       [ 0.00312543, -0.00632926,  0.01026588, -0.00706205],\n",
      "       ...,\n",
      "       [-0.01006098, -0.00025011,  0.0119477 , -0.00163662],\n",
      "       [-0.01270853,  0.00809463, -0.00161246,  0.00622636],\n",
      "       [ 0.01346563, -0.00197507, -0.00591334, -0.00557721]],\n",
      "      dtype=float32)>]]\n"
     ]
    }
   ],
   "source": [
    "print('損失', loss(train_t, model(train_v)))\n",
    "print('勾配', dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=loss,\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10684 samples, validate on 1336 samples\n",
      "Epoch 1/10\n",
      "10684/10684 - 1s - loss: 1.2189 - accuracy: 0.6482 - val_loss: 1.1157 - val_accuracy: 0.7478\n",
      "Epoch 2/10\n",
      "10684/10684 - 1s - loss: 1.0512 - accuracy: 0.7651 - val_loss: 0.9939 - val_accuracy: 0.7657\n",
      "Epoch 3/10\n",
      "10684/10684 - 1s - loss: 0.9540 - accuracy: 0.7742 - val_loss: 0.9165 - val_accuracy: 0.7672\n",
      "Epoch 4/10\n",
      "10684/10684 - 1s - loss: 0.8893 - accuracy: 0.7765 - val_loss: 0.8618 - val_accuracy: 0.7665\n",
      "Epoch 5/10\n",
      "10684/10684 - 1s - loss: 0.8421 - accuracy: 0.7770 - val_loss: 0.8202 - val_accuracy: 0.7680\n",
      "Epoch 6/10\n",
      "10684/10684 - 1s - loss: 0.8055 - accuracy: 0.7775 - val_loss: 0.7869 - val_accuracy: 0.7710\n",
      "Epoch 7/10\n",
      "10684/10684 - 1s - loss: 0.7757 - accuracy: 0.7777 - val_loss: 0.7592 - val_accuracy: 0.7717\n",
      "Epoch 8/10\n",
      "10684/10684 - 1s - loss: 0.7507 - accuracy: 0.7781 - val_loss: 0.7355 - val_accuracy: 0.7717\n",
      "Epoch 9/10\n",
      "10684/10684 - 1s - loss: 0.7292 - accuracy: 0.7783 - val_loss: 0.7150 - val_accuracy: 0.7732\n",
      "Epoch 10/10\n",
      "10684/10684 - 1s - loss: 0.7103 - accuracy: 0.7790 - val_loss: 0.6968 - val_accuracy: 0.7725\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_v,train_t,\n",
    "                    epochs=10, \n",
    "                    validation_data=(valid_v, valid_t),\n",
    "                    verbose=2\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
